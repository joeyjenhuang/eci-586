---
title: 'Unit 0: Getting Started Case Study'
subtitle: 'ECI 586 Intro to Learning Analytics'
author: "YOUR NAME HERE"
date: "`r format(Sys.Date(),'%B %e, %Y')`"
format:
  html:
    toc: true
    toc-location: right
theme:
  light: simplex
  dark: cyborg
editor: visual
bibliography: lit/references.bib
---

## 0. INTRODUCTION

### Background

Welcome to using **ECI 586: An Introduction to Learning Analytics**! During the third week of each unit, we'll complete a basic research workflow, or data analysis process, modeled after an actual learning analytics study. This getting started task is designed to orient you to both our data analysis assignments and to R, RStudio, and/or RMarkdown, which we'll be using to complete those assignments.

We'll be using Posit Cloud, which has all of the functionality of the RStudio Desktop, and some additional benefits for the those new to R, such as the pre-installation of packages and the simplification of file directories. If you're new to R, I highly recommend it.

You are also welcome to use RStudio Desktop, and you can download this project on our course workspace by clicking the "Export" button shown in the following screenshot:

![](img/project-export.png){width="80%"}

### Organization

This independent practice is really a warm-up. It is a chance to become familiar with how RStudio works. In the context of doing so, we'll focus on three things:

1.  Reading data into R (in the **Prepare** section)
2.  Preparing and "wrangling" data in table (think spreadsheet!) format (in the **Wrangle** section)
3.  Creating some plots (in the **Explore** section)
4.  Running a model - specifically, a regression model (in the **Model** section)
5.  Finally, creating a reproducible report of your work you can share with others (in the **Communicate** section)

### How to use this document

What you are working in now is a [Quarto](https://quarto.org) markdown file as indicated by the .qmd file name extension. Following best practices for reproducible research [@gandrud2021], Quarto files store information in plain text [markdown](https://bookdown.org/yihui/rmarkdown/markdown-syntax.html) syntax. R Markdown documents are fully reproducible and use a productive notebook interface to combine narrative text and "chunks" of code to produce [a range of static or dynamic outputs formats](https://quarto.org/docs/guide/) including: HTML,Â PDF,Â MS Word,Â HTML5 slides,Â Tufte-style handouts, books, dashboards, shiny applications, research articles,Â websites, and more.

There are two keys to your use of Quarto for this activity:

1.  First, be sure that you are viewing the document in the "Visual Editor" mode. You can use this mode by clicking the word "Visual" on the left side of the toolbar above. The visual editor allows you to view formatted headers, text and code chunks as specified by the underlying markdown syntax, or "Source" text. Visual mode is a bit more "human readable" than markdown syntax but definitely take a look at the source text.
2.  Second, note the specially formatted text box below called a "[code chunk](#0)." These chunks allows you to run code from [multiple languages](#0) including R, Python, and SQL. This specific code chunk contains a line of R code as specified by "r" inside the curly brackets `{}` where you can also include other "[chunk options](https://yihui.org/knitr/options/#chunk-options)." You will also notice a set of buttons in the upper right corner for running the code.

Click the arrow to the right of the code chunk below to view the image (more on that process of clicking the green arrow and what it does, too, in a moment)!

```{r}
knitr::include_graphics("img/laser-cycle.png")
```

### The Data-Intensive Research Workflow

You may have noticed that the words in this diagram correspond to the sections outlined at the beginning of this document. These terms, or processes, are part of a framework called the data-intensive research workflow and comes from the book [Learning Analytics Goes to School](https://www.routledge.com/Learning-Analytics-Goes-to-School-A-Collaborative-Approach-to-Improving/Krumm-Means-Bienkowski/p/book/9781138121836) [@krumm2018]*.* You can check that out (literally, it's available online through the NCSU Library), but don't feel any need to dive deep for now - we'll be spending more time on this process throughout the course. For now, know that this document and our unit case studies is organized around these five components of the Data Intensive Research Workflow.

Now, let's get started!

## 1. PREPARE

By preparing, we refer to developing a question or purpose for the analysis, which can be surprisingly difficult when considering its utility for helping educators improve teaching and learning! This part of the process also involves developing an understanding of the data and what you may need to analyze the data. Often this involves looking at the data and its documentation. For now, we'll focus on just a few parts of this process, diving in much more deeply over the coming weeks.

### Packages ðŸ“¦

![](img/tidyverse.png){width="40%"}

R uses "packages," add-ons that enhance its functionality. One package that we'll be using is the tidyverse. The {tidyverse} package is actually a [collection of R](https://www.tidyverse.org/packages) packages designed for reading, wrangling, and exploring data and which all share an underlying design philosophy, grammar, and data structures.

Before we can begin using these packages, we will need to install them using the `install.packages()` function built into R.

Click the green arrow in the right corner of the block-or "chunk"-of code that follows and see if you can identify which packages have been installed in the console below.

```{r, eval=FALSE}
install.packages("tidyverse")
```

Once these packages have been installed, we will need to load them in order to use the handy functions they contain.

To load the tidyverse, click the green arrow in the right corner of the block-or "chunk"-of code that follows. Notice that we do not need to use the quotation marks again because the {tidyverse} package and packages it contains are now a part of our package library!

```{r}
library(tidyverse)
```

Please do not worry if you saw a number of "messages:" those probably mean that the tidyverse loaded just fine. If you see an error, though, try to interpret or search via your search engine the contents of the error, or reach out to us for assistance.

### Loading (or reading in) data

Next, we'll load data - specifically, a CSV file, the kind that you can export from Microsoft Excel or Google Sheets - into R, using the `read_csv()` function in the next chunk.

Clicking the green arrow runs the code; do that next.

```{r}
sci_data <- read_csv("data/sci-online-classes.csv")
```

Notice that we "assigned" our data set to a new object in R named `sci_data` that will now be saved in your "Environment" pane in the upper right corner of RStudio. Go ahead and take a look to make sure it's there.

![](img/environment-pane.png){width="80%"}

#### [**Your Turn**]{style="color: green;"} **â¤µ**

Why do you think we included `data/` before our `sci-online-classes.csv` file? Why quotation marks?

Add your responses after the dashes below:

-   YOUR RESPONSE HERE

Hint: check the files pane in the lower right corner of RStudio.

#### Viewing or inspecting data

Last, let's check that the code worked as we intended; run the next chunk and look at the results, tabbing left or right with the arrows, or scanning through the rows by clicking the numbers at the bottom of the pane with the print-out of the data you loaded:

```{r}
sci_data
```

#### [**Your Turn**]{style="color: green;"} **â¤µ**

What do you notice about this dataset? What do you wonder? Add one or two thoughts after the dash below:

-   YOUR RESPONSE HERE

There are other ways to inspect your data; the `glimpse()` function provides one such way. Run the code below to take a glimpse at your data.

```{r}
glimpse(sci_data)
```

Generally, rows typically represent "cases," the units that we measure, or the units on which we collect data. What counts as a "case" (and therefore what is represented as a row) varies by (and within) fields. There may be multiple types or levels of units studied in your field; listing more than one is fine! Also, please consider what columns - which usually represent variables - represent in your area of work and/or research.

#### [**Your Turn**]{style="color: green;"} **â¤µ**

How many "cases" or observations are in this data set?

-   YOUR RESPONSE HERE

Pick two columns (or more) and write what you think it represents:

-   YOUR RESPONSE HERE

Next, we'll use a few functions that are handy for preparing data in table form.

## 2. WRANGLE

By wrangle, we refer to the process of cleaning and processing data, and, in cases, merging (or joining) data from multiple sources. Often, this part of the process is very (surprisingly) time-intensive. Wrangling your data into shape can itself be an important accomplishment! There are great tools in R to do this, especially through the use of the {dplyr} R package.

### Selecting variables

Let's select only a few variables by typing our dataset `sci_data` and "passing" that using the `|>` operator to the `select()` function from the {dplyr} package:

```{r}
sci_data |> 
  select(student_id, 
         total_points_possible,
         total_points_earned, 
         TimeSpent)
```

Notice how the number of columns (variables) is now different.

Let's *include one additional variable* in your select function.

First, we need to figure out what variables exist in our dataset (or be reminded of this - it's very common in R to be continually checking and inspecting your data)!

In addition to `glimpse()` function, you can use a function named `View()` to do this. Try it out and see what happens!

```{r, eval=FALSE}
View(sci_data)
```

#### [**Your Turn**]{style="color: green;"} **â¤µ**

In the code chunk below, add a new variable to the code, being careful to type the new variable name as it appears in the data. I've added some code to get you started. Consider how the names of the other variables are separated as you think about how to add an additional variable to this code.

```{r}
sci_data |> 
  select(student_id, 
         total_points_possible,
         total_points_earned, 
         TimeSpent)
```

Once added, the output should be different than in the code above - there should now be an additional variable included in the print-out.

### Filtering variables

Next, let's explore filtering variables. Check out and run the next chunk of code, imagining that we wish to filter our data to view only the rows associated with students who earned a final grade (as a percentage) of 70 - 70% - or higher.

```{r}
sci_data |> 
  filter(FinalGradeCEMS > 70)
```

#### [**Your Turn**]{style="color: green;"} **â¤µ**

In the next code chunk, change the cut-off from 70% to some other value - larger or smaller (maybe much larger or smaller - feel free to play around with the code a bit!).

```{r}
sci_data |> 
  filter(FinalGradeCEMS > 70)
```

What happens when you change the cut-off from 70 to something else? Add a thought (or more):

-   YOUR RESPONSE HERE

### Arrange

The last function we'll use for preparing tables is arrange.

We'll combine this `arrange()` function with a function we used already - `select()`. We do this so we can view only the student ID and their final grade.

```{r}
sci_data |> 
  select(student_id, FinalGradeCEMS) |>
  arrange(FinalGradeCEMS)
```

Note that arrange works by sorting values in ascending order (from lowest to highest); you can change this by using the desc() function with arrange, like the following:

```{r}
sci_data |> 
  select(student_id, FinalGradeCEMS) |> 
  arrange(desc(FinalGradeCEMS))
```

#### [**Your Turn**]{style="color: green;"} **â¤µ**

In the code chunk below, replace FinalGradeCEMS that is used with both the `select()` and `arrange()` functions with a different variable in the data set. Consider returning to the code chunk above in which you glimpsed at the names of all of the variables.

```{r}
sci_data |>  
  select(student_id, FinalGradeCEMS) |>
  arrange(desc(FinalGradeCEMS))
```

#### Optional

Can you compose a series of functions that include the `select()`, `filter()`, and arrange functions? Recall that you can "pipe" the output from one function to the next as when we used select() and arrange() together in the code chunk above.

*This optional activity is not required/necessary to complete; it's just for those who wish to do a bit more with these functions at this time (we'll do more in class, too!)*

```{r}

```

## 3. EXPLORE

Exploratory data analysis, or exploring your data, involves processes of *describing* your data (such as by calculating the means and standard deviations of numeric variables, or counting the frequency of categorical variables) and, often, visualizing your data prior to modeling. In this section, we'll create a few plots to explore our data.

### Histogram

The code below creates a histogram, or a distribution of the values, in this case for students' final grades.

```{r}
ggplot(sci_data, aes(x = FinalGradeCEMS)) +
  geom_histogram()
```

You can change the color of the histogram bars by specifying a color as follows:

```{r}
ggplot(sci_data, aes(x = FinalGradeCEMS)) +
  geom_histogram(fill = "blue")
```

### Changing colors

#### [**Your Turn**]{style="color: green;"} **â¤µ**

In the code chunk below, change the color to one of your choosing; consider this list of valid color names here: <http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf>

```{r}
ggplot(sci_data, aes(x = FinalGradeCEMS)) +
  geom_histogram(fill = "blue")
```

Finally, we'll make one more change; visualize the distribution of another variable in the data - one other than FinalGradeCEMS. You can do so by swapping out the name for another variable with FinalGradeCEMS. Also, change the color to one other than blue.

```{r}
ggplot(sci_data, aes(x = FinalGradeCEMS)) +
  geom_histogram(fill = "blue")
```

#### Optional

Completed the above? Nice job! Try creating a scatter plot for the relationship between two variables. You will need to pass the names of two variables to the code below for what is now simply XXX (a placeholder).

```{r, eval=FALSE}
ggplot(sci_data, aes(x = XXX, y = XXX)) +
  geom_point)
```

## 4. MODEL

"Model" is one of those terms that has many different meanings. For our purpose, we refer to the process of simplifying and summarizing our data. Thus, models can take many forms; calculating means represents a legitimate form of modeling data, as does estimating more complex models, including linear regressions, and models and algorithms associated with machine learning tasks. For now, we'll run a linear regression to predict students' final grades.

Below, we predict students' final grades `FinalGradeCEMS`, which is on a 0-100 point scale, on the basis of the time they spent on the course (measured through their learning management system in minutes, `TimeSpent`, and the `subject` (one of five) of their specific course.

```{r}
m1 <- lm(FinalGradeCEMS ~ TimeSpent_hours + subject, data = sci_data)
summary(m1)
```

There is a lot to unpack in this output, but for now the most important values to look at are those in the Estimate column, which represent the intercept and slopes for your linear regression model.

Note that the estimate for `TimeSpent` is 0.46 and statistically significant. We can interpret this as telling us that for every additional hour students spend on the course, the estimated value for their final grade will be 0.42 (on a 0-100 scale) greater than the intercept, which is around 57. So if a student spent, for instance, 40 hours on the course, their estimated final grade would be 57 + (.42 \* 40), or around 74.

#### [**Your Turn**]{style="color: green;"} **â¤µ**

Notice how above the variables are separated by a + symbol. Below, add *another* - a third - variable to the regression model. Specifically, add a variable for students' initial, self-reported interest in science, `int` - and any other variable(s) you like!

```{r}
m2 <- lm(FinalGradeCEMS ~ TimeSpent + subject, data = sci_data)
summary(m2)
```

What do you notice about the results? We're going to dive into this *much* more: if you have many questions now, you're in the right spot!

-   YOUR RESPONSE HERE

## 5. COMMUNICATE

Great job! Now that you've finished your coding activities, scroll back to the very top of this Quarto Document and change the `author: "YOUR NAME HERE"` to your actual name surrounded by quotation marks like so: `author: "Shaun Kellogg"`

Next, click the "Render" button in the toolbar at the top of your document to render this document to a HTML web page, just one of [the many publishing formats you can create with Quarto](https://quarto.org/docs/output-formats/all-formats.html) documents.

You should now see a new file named `unit-0-case-study.html` in the Files tab located in the bottom right corner of R Studio. If so, congratulations, you just completed the getting started activity! You're now ready for the unit Case Studies that we will complete during the third week of each unit.
