<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Dr.&nbsp;Shaun Kellogg">
<meta name="dcterms.date" content="2024-09-30">

<title>Explaining or Predicting Graduation Rates Using IPEDS</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="unit-2-case-study-key_files/libs/clipboard/clipboard.min.js"></script>
<script src="unit-2-case-study-key_files/libs/quarto-html/quarto.js"></script>
<script src="unit-2-case-study-key_files/libs/quarto-html/popper.min.js"></script>
<script src="unit-2-case-study-key_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="unit-2-case-study-key_files/libs/quarto-html/anchor.min.js"></script>
<link href="unit-2-case-study-key_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="unit-2-case-study-key_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="unit-2-case-study-key_files/libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="unit-2-case-study-key_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="unit-2-case-study-key_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="unit-2-case-study-key_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="unit-2-case-study-key_files/libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#prepare" id="toc-prepare" class="nav-link active" data-scroll-target="#prepare">1. PREPARE</a>
  <ul>
  <li><a href="#a.-conceptual-focus" id="toc-a.-conceptual-focus" class="nav-link" data-scroll-target="#a.-conceptual-focus">1a. Conceptual Focus</a>
  <ul class="collapse">
  <li><a href="#research-question" id="toc-research-question" class="nav-link" data-scroll-target="#research-question">Research Question</a></li>
  <li><a href="#literature-review" id="toc-literature-review" class="nav-link" data-scroll-target="#literature-review">Literature Review</a></li>
  <li><a href="#your-turn" id="toc-your-turn" class="nav-link" data-scroll-target="#your-turn"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  </ul></li>
  <li><a href="#b.-load-libraries" id="toc-b.-load-libraries" class="nav-link" data-scroll-target="#b.-load-libraries">1b. Load Libraries</a>
  <ul class="collapse">
  <li><a href="#tidymodels" id="toc-tidymodels" class="nav-link" data-scroll-target="#tidymodels">tidymodels 📦</a></li>
  <li><a href="#your-turn-1" id="toc-your-turn-1" class="nav-link" data-scroll-target="#your-turn-1"><span style="color: green;"><strong>Your Turn</strong></span> <strong>⤵</strong></a></li>
  </ul></li>
  <li><a href="#c.-import-inspect-data" id="toc-c.-import-inspect-data" class="nav-link" data-scroll-target="#c.-import-inspect-data">1c. Import &amp; Inspect Data</a>
  <ul class="collapse">
  <li><a href="#your-turn-2" id="toc-your-turn-2" class="nav-link" data-scroll-target="#your-turn-2"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  <li><a href="#question" id="toc-question" class="nav-link" data-scroll-target="#question">❓Question</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#wrangle" id="toc-wrangle" class="nav-link" data-scroll-target="#wrangle">2. WRANGLE</a>
  <ul>
  <li><a href="#a.-select-variables" id="toc-a.-select-variables" class="nav-link" data-scroll-target="#a.-select-variables">2a. Select Variables</a>
  <ul class="collapse">
  <li><a href="#your-turn-3" id="toc-your-turn-3" class="nav-link" data-scroll-target="#your-turn-3"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  </ul></li>
  <li><a href="#b.-count-variables" id="toc-b.-count-variables" class="nav-link" data-scroll-target="#b.-count-variables">2b. Count Variables</a>
  <ul class="collapse">
  <li><a href="#your-turn-4" id="toc-your-turn-4" class="nav-link" data-scroll-target="#your-turn-4"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  </ul></li>
  <li><a href="#c.-filter-variables" id="toc-c.-filter-variables" class="nav-link" data-scroll-target="#c.-filter-variables">2c. Filter Variables</a>
  <ul class="collapse">
  <li><a href="#your-turn-5" id="toc-your-turn-5" class="nav-link" data-scroll-target="#your-turn-5"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  <li><a href="#your-turn-6" id="toc-your-turn-6" class="nav-link" data-scroll-target="#your-turn-6"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  </ul></li>
  </ul></li>
  <li><a href="#explore" id="toc-explore" class="nav-link" data-scroll-target="#explore">3. EXPLORE</a>
  <ul>
  <li><a href="#a.-examine-dependent-variable" id="toc-a.-examine-dependent-variable" class="nav-link" data-scroll-target="#a.-examine-dependent-variable">3a. Examine Dependent Variable</a>
  <ul class="collapse">
  <li><a href="#question-1" id="toc-question-1" class="nav-link" data-scroll-target="#question-1">❓Question</a></li>
  <li><a href="#your-turn-7" id="toc-your-turn-7" class="nav-link" data-scroll-target="#your-turn-7"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  </ul></li>
  <li><a href="#b.-dichotomoize-variables" id="toc-b.-dichotomoize-variables" class="nav-link" data-scroll-target="#b.-dichotomoize-variables">3b. Dichotomoize Variables</a>
  <ul class="collapse">
  <li><a href="#your-turn-8" id="toc-your-turn-8" class="nav-link" data-scroll-target="#your-turn-8"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  </ul></li>
  </ul></li>
  <li><a href="#model" id="toc-model" class="nav-link" data-scroll-target="#model">4. MODEL</a>
  <ul>
  <li><a href="#a.-statistical-inference" id="toc-a.-statistical-inference" class="nav-link" data-scroll-target="#a.-statistical-inference">4a. Statistical Inference</a>
  <ul class="collapse">
  <li><a href="#code-explanation" id="toc-code-explanation" class="nav-link" data-scroll-target="#code-explanation">Code Explanation</a></li>
  <li><a href="#output-interpretation" id="toc-output-interpretation" class="nav-link" data-scroll-target="#output-interpretation">Output Interpretation</a></li>
  <li><a href="#your-turn-9" id="toc-your-turn-9" class="nav-link" data-scroll-target="#your-turn-9"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  </ul></li>
  <li><a href="#a.-supervised-machine-learning" id="toc-a.-supervised-machine-learning" class="nav-link" data-scroll-target="#a.-supervised-machine-learning">4a. Supervised Machine Learning</a>
  <ul class="collapse">
  <li><a href="#step-1.-split-data" id="toc-step-1.-split-data" class="nav-link" data-scroll-target="#step-1.-split-data">Step 1. Split data</a></li>
  <li><a href="#your-turn-10" id="toc-your-turn-10" class="nav-link" data-scroll-target="#your-turn-10"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  <li><a href="#step-2-create-a-recipe" id="toc-step-2-create-a-recipe" class="nav-link" data-scroll-target="#step-2-create-a-recipe">Step 2: Create a “Recipe”</a></li>
  </ul></li>
  <li><a href="#step-3-specify-a-model" id="toc-step-3-specify-a-model" class="nav-link" data-scroll-target="#step-3-specify-a-model">Step 3: Specify a Model</a>
  <ul class="collapse">
  <li><a href="#your-turn-11" id="toc-your-turn-11" class="nav-link" data-scroll-target="#your-turn-11"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  <li><a href="#add-model-and-recipe-to-workflow" id="toc-add-model-and-recipe-to-workflow" class="nav-link" data-scroll-target="#add-model-and-recipe-to-workflow"><strong>Add Model and Recipe to Workflow</strong></a></li>
  </ul></li>
  <li><a href="#step-4-fit-model-to-training-data" id="toc-step-4-fit-model-to-training-data" class="nav-link" data-scroll-target="#step-4-fit-model-to-training-data">Step 4: Fit Model to Training Data</a>
  <ul class="collapse">
  <li><a href="#your-turn-12" id="toc-your-turn-12" class="nav-link" data-scroll-target="#your-turn-12"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  </ul></li>
  <li><a href="#step-5-assess-accuracty-on-test-data" id="toc-step-5-assess-accuracty-on-test-data" class="nav-link" data-scroll-target="#step-5-assess-accuracty-on-test-data">Step 5: Assess Accuracty on Test Data</a>
  <ul class="collapse">
  <li><a href="#accuracy-metrics" id="toc-accuracy-metrics" class="nav-link" data-scroll-target="#accuracy-metrics">Accuracy Metrics</a></li>
  <li><a href="#your-turn-13" id="toc-your-turn-13" class="nav-link" data-scroll-target="#your-turn-13"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  </ul></li>
  </ul></li>
  <li><a href="#communicate" id="toc-communicate" class="nav-link" data-scroll-target="#communicate">5. COMMUNICATE</a>
  <ul>
  <li><a href="#your-turn-14" id="toc-your-turn-14" class="nav-link" data-scroll-target="#your-turn-14"><strong>👉 Your Turn</strong> <strong>⤵</strong></a></li>
  <li><a href="#congratulations" id="toc-congratulations" class="nav-link" data-scroll-target="#congratulations">Congratulations!</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Explaining or Predicting Graduation Rates Using IPEDS</h1>
<p class="subtitle lead">ECI 586 Introduction to Learning Analytics</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Dr.&nbsp;Shaun Kellogg </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">September 30, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="prepare" class="level2">
<h2 class="anchored" data-anchor-id="prepare">1. PREPARE</h2>
<p>In Unit 2, we learn about five basic steps in a supervised machine learning process in addition to some other components of a learning analytics workflow. For example, to help prepare for analysis, we’ll first take a step back and think about how we want to use machine learning, and <em>predicting</em> is a key word. Many scholars have focused on predicting students who are <em>at-risk</em>: of dropping a course or not succeeding in it. In this introductory machine learning case study, we will cover the following workflow processes from <span class="citation" data-cites="krumm2018">Krumm, Means, and Bienkowski (<a href="#ref-krumm2018" role="doc-biblioref">2018</a>)</span> as we attempt to develop our own model for predicting student drop-out:</p>
<ol type="1">
<li><p><strong>Prepare</strong>: Prior to analysis, we’ll look at the context from which our data came, formulate a basic research question, and get introduced the {tidymodels} packages for machine learning.</p></li>
<li><p><strong>Wrangle</strong>: Wrangling data entails the work of cleaning, transforming, and merging data. In Part 2 we focus on importing CSV files and modifying some of our variables.</p></li>
<li><p><strong>Explore</strong>: We take a quick look at our variables of interest and do some basic “feature engineering” by creating some new variables we think will be predictive of students at risk.</p></li>
<li><p><strong>Model:</strong> We introduce five basic steps in a supervised machine learning process, focusing on the mechanics of <strong>making predictions</strong>.</p></li>
<li><p><strong>Communicate:</strong> To wrap up our case study, we’ll create our first “data product” and share our analyses and findings by creating our first web page using R Markdown.</p></li>
</ol>
<section id="a.-conceptual-focus" class="level3">
<h3 class="anchored" data-anchor-id="a.-conceptual-focus">1a. Conceptual Focus</h3>
<p>Conceptually, in this case study we focus on prediction, the primary goal of supervised machine learning, and how it differs from the goals of description or explanation, a goal of traditional statistical methods. The reading introduced below focuses on this distinction between prediction and description or explanation. It is one of the most widely-read papers in machine learning and articulates how machine learning differs from other kinds of statistical models. Breiman describes the difference in terms of <em>data modeling</em> (models for description and explanation) and <em>algorithmic modeling</em> (what we call prediction or machine learning models).</p>
<section id="research-question" class="level4">
<h4 class="anchored" data-anchor-id="research-question">Research Question</h4>
<p>Technically, we’ll focus on the core parts of doing a machine learning analysis in R. We’ll use the {<a href="https://www.tidymodels.org/">tidymodels</a>} set of R packages (add-ons) to do so. We use as recent study by Zong and Davis <span class="citation" data-cites="zong2024modeling">Zong and Davis (<a href="#ref-zong2024modeling" role="doc-biblioref">2024</a>)</span> as an inspiration for ours. These authors used inferential models to try to understand what relates to the graduation rates of around 700 four-year universities in the United States, predicting this outcome on the basis of student background, finance, academic and social environment, and retention rate independent variables. You can find this study in the <code>lit</code> folder if you are interested in taking a look.</p>
<p>However, to help anchor our analysis and provide us with some direction, we’ll focus on the following research question as we explore this new data set:</p>
<blockquote class="blockquote">
<p>How well can we predict drop out rates for among four-year universities?</p>
</blockquote>
</section>
<section id="literature-review" class="level4">
<h4 class="anchored" data-anchor-id="literature-review">Literature Review</h4>
<p><img src="img/breiman.png" class="img-fluid" style="width:50.0%"></p>
<p>Breiman, L. (2001). Statistical modeling: The two cultures (with comments and a rejoinder by the author). <em>Statistical Science, 16</em>(3), 199-231. <a href="https://projecteuclid.org/journals/statistical-science/volume-16/issue-3/Statistical-Modeling--The-Two-Cultures-with-comments-and-a/10.1214/ss/1009213726.pdf" class="uri">https://projecteuclid.org/journals/statistical-science/volume-16/issue-3/Statistical-Modeling--The-Two-Cultures-with-comments-and-a/10.1214/ss/1009213726.pdf</a></p>
<p><strong>Abstract</strong></p>
<p>There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.</p>
</section>
<section id="your-turn" class="level4">
<h4 class="anchored" data-anchor-id="your-turn"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>You can find this study in the <code>lit</code> folder as well. Open up the article and take quick scan of the article and note two observations you have about the article.</p>
<ul>
<li>OBSERVATION 1</li>
<li>OBSERVATION 2</li>
</ul>
</section>
</section>
<section id="b.-load-libraries" class="level3">
<h3 class="anchored" data-anchor-id="b.-load-libraries">1b. Load Libraries</h3>
<section id="tidymodels" class="level4">
<h4 class="anchored" data-anchor-id="tidymodels">tidymodels 📦</h4>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="img/tidymodels.svg" class="img-fluid quarto-figure quarto-figure-left figure-img" style="width:30.0%"></p>
</figure>
</div>
<p>The <a href="https://www.tidymodels.org">tidymodels</a> package is a “meta-package” for modeling and statistical analysis that shares the underlying design philosophy, grammar, and data structures of the <a href="https://www.tidyverse.org/">tidyverse</a>. Like the {tidyverse} package, it includes a core set of packages that are loaded on startup and contains tools for:</p>
<ul>
<li>data splitting and pre-processing;</li>
<li>model selection, tuning, and evaluation;</li>
<li>feature selection and variable importance estimation;</li>
<li>as well as other functionality.</li>
</ul>
</section>
<section id="your-turn-1" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-1"><span style="color: green;"><strong>Your Turn</strong></span> <strong>⤵</strong></h4>
<p>In addition to the {tidymodels} package, we’ll also be using the {tidyverse} packages we learned about in Unit 1, as well as the {janitor} package for quickly cleaning up variable names.</p>
<p>Use the code chunk below to load these three packages:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>✔ broom        1.0.6     ✔ recipes      1.1.0
✔ dials        1.3.0     ✔ rsample      1.2.1
✔ dplyr        1.1.4     ✔ tibble       3.2.1
✔ ggplot2      3.5.1     ✔ tidyr        1.3.1
✔ infer        1.0.7     ✔ tune         1.2.1
✔ modeldata    1.4.0     ✔ workflows    1.1.4
✔ parsnip      1.2.1     ✔ workflowsets 1.1.0
✔ purrr        1.0.2     ✔ yardstick    1.3.1</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ purrr::discard() masks scales::discard()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
✖ recipes::step()  masks stats::step()
• Dig deeper into tidy modeling with R at https://www.tmwr.org</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ forcats   1.0.0     ✔ readr     2.1.5
✔ lubridate 1.9.3     ✔ stringr   1.5.1</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ readr::col_factor() masks scales::col_factor()
✖ purrr::discard()    masks scales::discard()
✖ dplyr::filter()     masks stats::filter()
✖ stringr::fixed()    masks recipes::fixed()
✖ dplyr::lag()        masks stats::lag()
✖ readr::spec()       masks yardstick::spec()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(janitor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'janitor'

The following objects are masked from 'package:stats':

    chisq.test, fisher.test</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Remember to use the <code>library()</code> function to load these packages. After you’ve done that, click the green arrow to run the code chunk. If you see a bunch of messages (not anything labeled as an error), you are good to go! These messages mean the packages loaded correctly.</p>
</div>
</div>
</section>
</section>
<section id="c.-import-inspect-data" class="level3">
<h3 class="anchored" data-anchor-id="c.-import-inspect-data">1c. Import &amp; Inspect Data</h3>
<p>In this case study, we will be using a new data set from the <a href="https://nces.ed.gov/ipeds/">IPEDS, the Integrated Postsecondary Education Data System</a> and similar to the data set used by <span class="citation" data-cites="zong2024modeling">Zong and Davis (<a href="#ref-zong2024modeling" role="doc-biblioref">2024</a>)</span>.</p>
<p>Run the following code to read in the <code>ipeds-all-title-9-2022-data.csv</code> file using the <code>read_csv()</code> function, paying attention to where those files are located relative to this case study file – in the data folder!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>ipeds <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"data/ipeds-all-title-9-2022-data.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Rows: 5988 Columns: 24
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr  (9): institution name, HD2022.Postsecondary and Title IV institution in...
dbl (15): unitid, year, DRVADM2022.Percent admitted - total, DRVIC2022.Tuiti...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
</div>
</div>
<p>We’ll then use a handy function from janitor, <code>clean_names()</code>. It does what it seems like it should - it cleans the names of variables, making them easy to view and type. Run this next code chunk.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>ipeds <span class="ot">&lt;-</span> janitor<span class="sc">::</span><span class="fu">clean_names</span>(ipeds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="your-turn-2" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-2"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>In the chunk below, examine the data set using a function or means of your choice (such as just <em>printing</em> the data set by typing its name or using the <code>glimpse()</code> function). Do this in the code chunk below! Note its dimensions — especially how many rows it has!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>ipeds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5,988 × 24
   unitid institution_name    year hd2022_postsecondary…¹ drvadm2022_percent_a…²
    &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;                                   &lt;dbl&gt;
 1 100654 Alabama A &amp; M Uni…  2022 Title IV postsecondar…                     68
 2 100663 University of Ala…  2022 Title IV postsecondar…                     87
 3 100690 Amridge University  2022 Title IV postsecondar…                     NA
 4 100706 University of Ala…  2022 Title IV postsecondar…                     78
 5 100724 Alabama State Uni…  2022 Title IV postsecondar…                     97
 6 100733 University of Ala…  2022 Title IV postsecondar…                     NA
 7 100751 The University of…  2022 Title IV postsecondar…                     80
 8 100760 Central Alabama C…  2022 Title IV postsecondar…                     NA
 9 100812 Athens State Univ…  2022 Title IV postsecondar…                     NA
10 100830 Auburn University…  2022 Title IV postsecondar…                     92
# ℹ 5,978 more rows
# ℹ abbreviated names:
#   ¹​hd2022_postsecondary_and_title_iv_institution_indicator,
#   ²​drvadm2022_percent_admitted_total
# ℹ 19 more variables: drvic2022_tuition_and_fees_2021_22 &lt;dbl&gt;,
#   hd2022_institution_size_category &lt;chr&gt;, hd2022_state_abbreviation &lt;chr&gt;,
#   hd2022_carnegie_classification_2021_basic &lt;chr&gt;, …</code></pre>
</div>
</div>
<p>Now write down a couple observations after inspecting the data - and any all observations welcome!</p>
<ul>
<li>YOUR RESPONSE HERE</li>
<li>YOUR RESPONSE HERE</li>
</ul>
</section>
<section id="question" class="level4">
<h4 class="anchored" data-anchor-id="question">❓Question</h4>
<p>Recall that similar to <span class="citation" data-cites="zong2024modeling">Zong and Davis (<a href="#ref-zong2024modeling" role="doc-biblioref">2024</a>)</span>, we are trying to predict student drop out rates using data readily available to higher education researchers. Take a look at our data set again and list three variables you think might be useful for predicting graduation rates:</p>
<ul>
<li>VARIABLE 1</li>
<li>VARIABLE 2</li>
<li>VARIABLE 3</li>
</ul>
</section>
</section>
</section>
<section id="wrangle" class="level2">
<h2 class="anchored" data-anchor-id="wrangle">2. WRANGLE</h2>
<p>In general, data wrangling involves some combination of cleaning, reshaping, transforming, and merging data <span class="citation" data-cites="wickham2023r">Wickham, Çetinkaya-Rundel, and Grolemund (<a href="#ref-wickham2023r" role="doc-biblioref">2023</a>)</span>. The importance of data wrangling is difficult to overstate, as it involves the initial steps of going from raw data to a dataset that can be explored and modeled <span class="citation" data-cites="krumm2018">Krumm, Means, and Bienkowski (<a href="#ref-krumm2018" role="doc-biblioref">2018</a>)</span>. In Part 2, we focus on the the following wrangling processes to:</p>
<ol type="a">
<li><p><strong>Selecting Variables</strong>. We use the <code>select()</code> function to simultaneous select variables for analysis and rename exceptionally long variables.</p></li>
<li><p><strong>Filtering Variables.</strong> We use the <code>filter()</code> function to further reduce our data set to include only Title IV postsecondary institutions.</p></li>
</ol>
<section id="a.-select-variables" class="level3">
<h3 class="anchored" data-anchor-id="a.-select-variables">2a. Select Variables</h3>
<p>Even though we cleaned the names to make them easier to view and type (thanks, <code>clean_names()</code>)), they are still pretty long.</p>
<p>The code chunk below uses a very handy function, <code>select()</code>. This allows you to simultaneously choose and rename variables, returning a data frame with only the variables you have selected — named as you like. For now, we’ll just run this code. Later in your analyses, you’ll almost certainly use <code>select()</code> to get a more manageable dataset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>ipeds <span class="ot">&lt;-</span> ipeds <span class="sc">|&gt;</span> </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(<span class="at">name =</span> institution_name, </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">title_iv =</span> hd2022_postsecondary_and_title_iv_institution_indicator,</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>           <span class="at">carnegie_class =</span> hd2022_carnegie_classification_2021_basic,</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">state =</span> hd2022_state_abbreviation,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">total_enroll =</span> drvef2022_total_enrollment,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>           <span class="at">pct_admitted =</span> drvadm2022_percent_admitted_total,</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>           <span class="at">n_bach =</span> drvc2022_bachelors_degree,</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>           <span class="at">n_mast =</span> drvc2022_masters_degree,</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>           <span class="at">n_doc =</span> drvc2022_doctors_degree_research_scholarship,</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>           <span class="at">tuition_fees =</span> drvic2022_tuition_and_fees_2021_22,</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>           <span class="at">grad_rate =</span> drvgr2022_graduation_rate_total_cohort,</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>           <span class="at">percent_fin_aid =</span> sfa2122_percent_of_full_time_first_time_undergraduates_awarded_any_financial_aid,</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>           <span class="at">avg_salary =</span> drvhr2022_average_salary_equated_to_9_months_of_full_time_instructional_staff_all_ranks)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Before moving on, let’s make sure we understand what each variables represents. Even though the variables names are fairly intuitive, below is a breif description of variables we just selected:</p>
<ul>
<li><p>name: Institution name</p></li>
<li><p><strong>title_iv</strong>: Indicator if the university is Title IV eligible</p></li>
<li><p><strong>carnegie_class</strong>: Carnegie Classification of the institution</p></li>
<li><p><strong>state</strong>: State abbreviation</p></li>
<li><p><strong>total_enroll</strong>: Total enrollment</p></li>
<li><p><strong>pct_admitted</strong>: Percentage of applicants admitted</p></li>
<li><p><strong>n_bach</strong>: Number of students receiving a bachelor’s degree</p></li>
<li><p><strong>n_mast</strong>: Number receiving a master’s degree</p></li>
<li><p><strong>n_doc</strong>: Number receiving a doctoral degree</p></li>
<li><p><strong>tuition_fees</strong>: Total cost of tuition and fees</p></li>
<li><p><strong>grad_rate</strong>: Graduation rate</p></li>
<li><p><strong>percent_fin_aid</strong>: Percent of students receiving financial aid</p></li>
<li><p><strong>avg_salary</strong>: Average salary of instructional staff</p></li>
</ul>
<p>Sometimes publicly available data sets, particularly high-quality ones like IPEDS, will have a <strong>codebook</strong> or <strong>glossary</strong> to help that provides detailed information about a dataset, serving as a guide to understanding the structure, contents, and variables within the data. It essentially acts as a “dictionary” for your dataset, helping researchers, analysts, and anyone else using the data to interpret it correctly.</p>
<section id="your-turn-3" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-3"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>Visit the the IPEDS glossary located here: <a href="https://surveys.nces.ed.gov/ipeds/public/glossary" class="uri">https://surveys.nces.ed.gov/ipeds/public/glossary</a></p>
<p>Use the glossary to look up a variable from above or in our larger data set that you are interested in understanding better and record the full definition below:</p>
<ul>
<li>DEFINITION</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Fun fact</strong>: RTI International – located in the North Carolina’s Research Triangle Park and from which they derive their name – has led IPEDS for over 20 years, collecting institution-level data from primary providers of postsecondary education nationwide. To learn more about their work visit: <a href="https://www.rti.org/impact/integrated-postsecondary-education-data-system-ipeds" class="uri">https://www.rti.org/impact/integrated-postsecondary-education-data-system-ipeds</a></p>
</div>
</div>
</section>
</section>
<section id="b.-count-variables" class="level3">
<h3 class="anchored" data-anchor-id="b.-count-variables">2b. Count Variables</h3>
<p>As illustrated in the figure below, <span class="citation" data-cites="krumm2018">Krumm, Means, and Bienkowski (<a href="#ref-krumm2018" role="doc-biblioref">2018</a>)</span> noted in Chapter 2 of <em>Learning Analytics goes to Schools,</em> processes in the Data-Intensive Research Workflow workflow (e.g., preparing, wrangling, exploring, etc.) are more can be seens as overlapping activities as much as distinct sequentional steps.</p>
<p><img src="img/workflow-overlap.png" class="img-fluid" style="width:80.0%"></p>
<p>For example, next we will explore our data a little bit to assist with our data wrangling process.</p>
<p>A useful function for exploring data is <code>count()</code>; it does what it sounds like! It counts how many times values for a variable appear.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>ipeds <span class="sc">|&gt;</span> </span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">count</span>(title_iv)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 2
  title_iv                                             n
  &lt;chr&gt;                                            &lt;int&gt;
1 Title IV NOT primarily postsecondary institution    30
2 Title IV postsecondary institution                5958</code></pre>
</div>
</div>
<p>This suggests we may wish to filter the 30 non-Title IV institutions — something we’ll do shortly.</p>
<section id="your-turn-4" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-4"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>Can you count another variable? Pick another (see the code chunk two above) and add a count below. While simple, counting up different values in our data can be very informative (and can often lead to further explorations)!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>ipeds <span class="sc">|&gt;</span> </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">count</span>(carnegie_class)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 34 × 2
   carnegie_class                                                              n
   &lt;chr&gt;                                                                   &lt;int&gt;
 1 Associate's Colleges: High Career &amp; Technical-High Nontraditional          88
 2 Associate's Colleges: High Career &amp; Technical-High Traditional            106
 3 Associate's Colleges: High Career &amp; Technical-Mixed Traditional/Nontra…   116
 4 Associate's Colleges: High Transfer-High Nontraditional                   105
 5 Associate's Colleges: High Transfer-High Traditional                      105
 6 Associate's Colleges: High Transfer-Mixed Traditional/Nontraditional      101
 7 Associate's Colleges: Mixed Transfer/Career &amp; Technical-High Nontradit…   114
 8 Associate's Colleges: Mixed Transfer/Career &amp; Technical-High Tradition…   104
 9 Associate's Colleges: Mixed Transfer/Career &amp; Technical-Mixed Traditio…    97
10 Baccalaureate Colleges: Arts &amp; Sciences Focus                             216
# ℹ 24 more rows</code></pre>
</div>
</div>
</section>
</section>
<section id="c.-filter-variables" class="level3">
<h3 class="anchored" data-anchor-id="c.-filter-variables">2c. Filter Variables</h3>
<p>Our final data wrangling step is filtering our data set to include only Title IV postsecondary institutions.</p>
<p>We’ll do this with a function you should now be fairly familiar with. <code>filter()</code> is a very handy function that is part of the tidyverse; it filters to <em>include</em> (or <em>exclude</em>) observations in your data based upon logical conditions (e.g., <code>==</code>, <code>&gt;</code>, <code>&lt;=</code>, etc.). See more <a href="https://dplyr.tidyverse.org/reference/filter.html">here</a> if interested.</p>
<p>Run the code chunk below to filter the data so it only includes only Title IV postsecondary institutions.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>ipeds <span class="ot">&lt;-</span> ipeds <span class="sc">|&gt;</span> </span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(title_iv <span class="sc">==</span> <span class="st">"Title IV postsecondary institution"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="your-turn-5" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-5"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>Can you filter the data again, this time to <em>only</em> include institutions with a carnegie classification?</p>
<p>In other words, can you exclude those institutions with a value for the <code>carnegie_class</code> variable that is “Not applicable, not in Carnegie universe (not accredited or nondegree-granting)”)?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>ipeds <span class="ot">&lt;-</span> ipeds <span class="sc">|&gt;</span> </span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(carnegie_class <span class="sc">!=</span> <span class="st">"Not applicable, not in Carnegie universe (not accredited or nondegree-granting)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Whereas the logical operator <code>==</code> is used to include only matching conditions, the logical operator <code>!=</code> excludes matching conditions.</p>
</div>
</div>
</section>
<section id="your-turn-6" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-6"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>We’re cruising! Let’s take another peak at our data - using <code>glimpse()</code> or another means of your choosing below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(ipeds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Rows: 3,818
Columns: 13
$ name            &lt;chr&gt; "Alabama A &amp; M University", "University of Alabama at …
$ title_iv        &lt;chr&gt; "Title IV postsecondary institution", "Title IV postse…
$ carnegie_class  &lt;chr&gt; "Master's Colleges &amp; Universities: Larger Programs", "…
$ state           &lt;chr&gt; "Alabama", "Alabama", "Alabama", "Alabama", "Alabama",…
$ total_enroll    &lt;dbl&gt; 6007, 21639, 647, 9237, 3828, 38644, 1777, 2894, 5109,…
$ pct_admitted    &lt;dbl&gt; 68, 87, NA, 78, 97, 80, NA, NA, 92, 44, 57, NA, NA, NA…
$ n_bach          &lt;dbl&gt; 511, 2785, 54, 1624, 480, 6740, NA, 738, 672, 5653, 26…
$ n_mast          &lt;dbl&gt; 249, 2512, 96, 570, 119, 2180, NA, 80, 300, 1415, 0, N…
$ n_doc           &lt;dbl&gt; 9, 166, 20, 41, 2, 215, NA, 0, 0, 284, 0, NA, 0, NA, N…
$ tuition_fees    &lt;dbl&gt; 10024, 8568, NA, 11488, 11068, 11620, 4930, NA, 8860, …
$ grad_rate       &lt;dbl&gt; 27, 64, 50, 63, 28, 73, 22, NA, 36, 81, 65, 26, 9, 29,…
$ percent_fin_aid &lt;dbl&gt; 87, 96, NA, 96, 97, 87, 87, NA, 99, 79, 100, 96, 92, 8…
$ avg_salary      &lt;dbl&gt; 77824, 106434, 36637, 92561, 72635, 97394, 63494, 8140…</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="explore" class="level2">
<h2 class="anchored" data-anchor-id="explore">3. EXPLORE</h2>
<p>As noted by <span class="citation" data-cites="krumm2018">Krumm, Means, and Bienkowski (<a href="#ref-krumm2018" role="doc-biblioref">2018</a>)</span>, exploratory data analysis often involves some combination of data visualization and feature engineering. In Part 3, we will create some quick visualization to help us better understand our data and transform our dependent variable from continuous to categorical to simplify our modeling. Specifically, in Part 3 we will:</p>
<ol type="a">
<li><p><strong>Visualize Variables</strong> by using the {ggplot2} pacakge to visually inspect our <code>grad_rate</code> dependent variable as well as other variables of interest.</p></li>
<li><p><strong>Dichotomize Dependent Variable</strong> by “mutating” our <code>grad_rate</code> dependent variable from our continuous variable to a dichotomous variable.</p></li>
</ol>
<section id="a.-examine-dependent-variable" class="level3">
<h3 class="anchored" data-anchor-id="a.-examine-dependent-variable">3a. Examine Dependent Variable</h3>
<p>One key step in most analyses is to explore the data. Here, we conduct an exploratory data analysis with the IPEDS data, focusing on the key outcome of graduate rate.</p>
<p>Below, we use the ggplot2 package (part of the tidyverse) to visualize the <em>spread</em> of the values of our dependent variable, <code>grad_rate</code>, which represents institutions’ graduation rate. There is a <em>lot</em> to ggplot2, and data visualizations are not the focus of this module, but <a href="https://ggplot2.tidyverse.org/">this web page</a> has a lot of information you can use to learn more, if you are interested. ggplot2 is fantastic for creating publication-ready visualizations!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>ipeds <span class="sc">|&gt;</span> </span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> grad_rate)) <span class="sc">+</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Removed 418 rows containing non-finite outside the scale range
(`stat_bin()`).</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="unit-2-case-study-key_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<section id="question-1" class="level4">
<h4 class="anchored" data-anchor-id="question-1">❓Question</h4>
<p>What do you notice about this graph – and about graduation rate?</p>
<ul>
<li>YOUR RESPONSE</li>
<li>YOUR RESPONSE</li>
</ul>
</section>
<section id="your-turn-7" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-7"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>Below, can you add one ggplot2 plot with a different variable/variables? Use the ggplot2 page linked above (also <a href="https://ggplot2.tidyverse.org/">here</a>) or the code above as a starting point (another histogram is fine!) for your visualization.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>ipeds <span class="sc">|&gt;</span> </span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> pct_admitted)) <span class="sc">+</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_histogram</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Removed 2040 rows containing non-finite outside the scale range
(`stat_bin()`).</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="unit-2-case-study-key_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>ipeds <span class="sc">|&gt;</span> </span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> tuition_fees, <span class="at">y =</span> total_enroll, <span class="at">color =</span> avg_salary)) <span class="sc">+</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Removed 599 rows containing missing values or values outside the scale range
(`geom_point()`).</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="unit-2-case-study-key_files/figure-html/unnamed-chunk-12-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="b.-dichotomoize-variables" class="level3">
<h3 class="anchored" data-anchor-id="b.-dichotomoize-variables">3b. Dichotomoize Variables</h3>
<p>Next we’ll again overlap our data wrangling and exploring activities in preparation for some data modeling that will come next. Recall that we are interested in assessing how we we can predict graduation rates, our <strong>dependent variable</strong>, using other variables or <strong>predictors</strong> in our data set.</p>
<p>Supervised machine learning, or predictive modeling, involves two broad approaches: classification and regression.</p>
<ul>
<li><p><strong>Classification</strong> algorithms model categorical outcomes (e.g., yes or no outcomes);</p></li>
<li><p><strong>Regression</strong> algorithms characterize continuous outcomes (e.g., test scores).</p></li>
</ul>
<p>To simplify our analysis for this case study, we’ll focus on classification. Specifically, we will model our dependent variable, <code>grad_rate</code>, as a dichotomous (i.e., yes or no; 1 or 0) dependent variable. This isn’t necessary, but it makes the contrast between the regression and supervised machine learning model a bit more vivid, and also dichotomous and categorical outcome variables are common in supervised machine learning applications, and so we’ll do this for this case study.</p>
<section id="your-turn-8" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-8"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>Your next task is to decide what constitutes a good graduation rate. Our only suggestion - don’t pick a number <em>too</em> close to 0% or 100%. Otherwise, please replace XXX below with the number from 0-100 that represents the graduation rate percentage. Just add the number – don’t add the percentage symbol.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>ipeds <span class="ot">&lt;-</span> ipeds <span class="sc">|&gt;</span> </span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">good_grad_rate =</span> <span class="fu">if_else</span>(grad_rate <span class="sc">&gt;</span> <span class="dv">66</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">good_grad_rate =</span> <span class="fu">as.factor</span>(good_grad_rate))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, add a reason or two for how and why you picked the number you did:</p>
<ul>
<li><p>REASON 1</p></li>
<li><p>REASON 2</p></li>
</ul>
<p>Before moving on, let’s unpack what we just did in the few lines of code above. The code is performing two primary operations on our <code>ipeds</code> dataset using the <code>mutate()</code> function from the <code>dplyr</code> package:</p>
<ol type="1">
<li><strong>Creating a New Variable <code>good_grad_rate</code>:</strong>
<ul>
<li>The <code>mutate()</code> function adds a new variable named <code>good_grad_rate</code> to the <code>ipeds</code> dataset.</li>
<li><code>if_else(grad_rate &gt; XXX, 1, 0)</code>: This part creates a binary (0 or 1) variable based on the <code>grad_rate</code> column.
<ul>
<li>If <code>grad_rate</code> is greater than <code>XXX</code> (where <code>XXX</code> is a placeholder value that needs to be specified), the value of <code>good_grad_rate</code> will be <code>1</code>.</li>
<li>If <code>grad_rate</code> is not greater than <code>XXX</code>, the value of <code>good_grad_rate</code> will be <code>0</code>.</li>
</ul></li>
</ul></li>
<li><strong>Converting <code>good_grad_rate</code> to a Factor:</strong>
<ul>
<li><code>good_grad_rate = as.factor(good_grad_rate)</code>: This part converts the <code>good_grad_rate</code> variable from a numeric type (0 or 1) to a factor type. Factors are useful in R for categorical data, and they help in modeling processes where the variable is treated as a categorical predictor or outcome variable.</li>
</ul></li>
</ol>
<p>In summary, the code is creating a new categorical variable <code>good_grad_rate</code> in the <code>ipeds</code> dataset that indicates whether the graduation rate (<code>grad_rate</code>) is above a specified threshold (<code>XXX</code>) and then converts this variable into a factor type with two levels: <code>0</code> (not above the threshold) and <code>1</code> (above the threshold).</p>
</section>
</section>
</section>
<section id="model" class="level2">
<h2 class="anchored" data-anchor-id="model">4. MODEL</h2>
<p>Models can be used for statistical inference, that is to test scientific hypotheses and understand the relationship between variables and an outcomes, or in the case of machine learning, can be use primarily for the purpose of predicting an outcome as accurately as possible. In this section we revisit the use of regression models for statistical inference, and then compare the use of the same model for the purpose of prediction.</p>
<p>Note that in Chapter 3, <span class="citation" data-cites="krumm2018">Krumm, Means, and Bienkowski (<a href="#ref-krumm2018" role="doc-biblioref">2018</a>)</span> highlight that the term <strong>regression</strong> can take on different meanings across inference and prediction uses:</p>
<blockquote class="blockquote">
<p>From a statistical, or inferential perspective, regression denotes a family of models that can be used on either categorical or continuous outcomes. Perhaps most confusing to newcomers or to researchers steeped in either inference or prediction are the ways in which specific models, such as logistic regression, can be used for either inference or classification.</p>
</blockquote>
<p>In both sections below we use <strong>logistic regression</strong>, a statistical method used to model the relationship between one or more independent variables (predictors) and a binary outcome (dependent variable). In the context of machine learning, this is considered a classification problem since we are trying to build a model that can “classify” or label data based on patterns in inherent in the data itself.</p>
<section id="a.-statistical-inference" class="level3">
<h3 class="anchored" data-anchor-id="a.-statistical-inference">4a. Statistical Inference</h3>
<p>We’ll first conduct a simple regression analysis from a statistical inference perspective, similar to what we did in Unit 1 for our virtual public school data.</p>
<p>Run the code chunk below to “fit” generalized linear model <code>glm()</code> function, due to the dependent variable being dichotomous:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(good_grad_rate <span class="sc">~</span> </span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>            total_enroll <span class="sc">+</span> </span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>            pct_admitted <span class="sc">+</span> </span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>            n_bach <span class="sc">+</span> </span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>            n_mast <span class="sc">+</span> </span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>            n_doc <span class="sc">+</span> </span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>            tuition_fees <span class="sc">+</span> </span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>            percent_fin_aid <span class="sc">+</span> </span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>            avg_salary, </span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>          <span class="at">data =</span> ipeds, </span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>          <span class="at">family =</span> <span class="st">"binomial"</span>) </span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m1) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = good_grad_rate ~ total_enroll + pct_admitted + 
    n_bach + n_mast + n_doc + tuition_fees + percent_fin_aid + 
    avg_salary, family = "binomial", data = ipeds)

Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)     -4.732e-01  7.276e-01  -0.650 0.515466    
total_enroll    -1.054e-04  4.649e-05  -2.267 0.023415 *  
pct_admitted    -1.357e-02  3.959e-03  -3.427 0.000610 ***
n_bach           7.563e-04  1.981e-04   3.817 0.000135 ***
n_mast          -4.373e-04  2.131e-04  -2.052 0.040140 *  
n_doc            5.749e-03  1.520e-03   3.782 0.000156 ***
tuition_fees     7.245e-05  5.630e-06  12.868  &lt; 2e-16 ***
percent_fin_aid -3.674e-02  6.666e-03  -5.512 3.56e-08 ***
avg_salary       2.599e-05  4.396e-06   5.912 3.39e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2034.8  on 1615  degrees of freedom
Residual deviance: 1369.5  on 1607  degrees of freedom
  (2202 observations deleted due to missingness)
AIC: 1387.5

Number of Fisher Scoring iterations: 6</code></pre>
</div>
</div>
<section id="code-explanation" class="level4">
<h4 class="anchored" data-anchor-id="code-explanation">Code Explanation</h4>
<p>The code is relatively straightforward but let’s breakdown what each line of code above is doing before interpreting the output of this model:</p>
<ol type="1">
<li><strong>Building a Logistic Regression Model (<code>glm</code>):</strong>
<ul>
<li><code>m1 &lt;- glm(...)</code>: This line creates a generalized linear model (GLM) and assigns it to the object <code>m1</code>.</li>
<li><code>good_grad_rate ~ ...</code>: The model is predicting <code>good_grad_rate</code>, a binary outcome variable that we created above, using multiple independent variables including <code>total_enroll</code>, <code>pct_admitted</code>, <code>n_bach</code>, <code>n_mast</code>, <code>n_doc</code>, <code>tuition_fees</code>, <code>percent_fin_aid</code>, and <code>avg_salary</code>.</li>
<li>The <code>family = "binomial"</code> argument specifies that this is a logistic regression model, which is appropriate when the dependent variable (<code>good_grad_rate</code>) is binary (0 or 1).</li>
</ul></li>
<li><strong>Displaying the Model Output (<code>summary(m1)</code>):</strong>
<ul>
<li>Finally, the <code>summary(m1)</code> function provides detailed information about the logistic regression model, which we save as <code>m1</code>, and includes:
<ul>
<li>Coefficients for each predictor variable.</li>
<li>Standard errors, z-values, and p-values for hypothesis testing.</li>
<li>Overall model statistics such as the null and residual deviance, indicating model fit.</li>
</ul></li>
</ul></li>
</ol>
<p>In summary, our code fits a logistic regression model to help us determine whether a university has a “good” graduation rate (<code>good_grad_rate</code>) based on several institutional characteristics. The <code>summary(m1)</code> output will show which predictors are statistically significant and how they influence the likelihood of a “good” graduation rate.</p>
</section>
<section id="output-interpretation" class="level4">
<h4 class="anchored" data-anchor-id="output-interpretation">Output Interpretation</h4>
<p>Now let’s focus on interpreting the output of <code>summary()</code> function and model. The table below provides the results of a logistic regression model predicting whether a university has a “good” graduation rate (<code>good_grad_rate</code>) using various institutional characteristics as predictors.</p>
<p><strong>Note:</strong> Your output will look a little different based on the cut-off point you selected for a “good” graduate rate. In my case, I somewhat arbitratily decided that if at least two-thirds (~67%) of students graduated, it was considered “good.”</p>
<p>Now let’s break down the interpretation. The table below provides estimates for each predictor, along with their standard errors, z-values, and p-values:</p>
<table class="table">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Predictor</th>
<th>Estimate</th>
<th>Std. Error</th>
<th>z value</th>
<th>Pr(&gt;</th>
<th>z</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(Intercept)</td>
<td>-0.4732</td>
<td>0.7276</td>
<td>-0.650</td>
<td>0.515466</td>
<td>(Not significant)</td>
</tr>
<tr class="even">
<td>total_enroll</td>
<td>-0.0001054</td>
<td>0.00004649</td>
<td>-2.267</td>
<td>0.023415</td>
<td>* Significant</td>
</tr>
<tr class="odd">
<td>pct_admitted</td>
<td>-0.01357</td>
<td>0.003959</td>
<td>-3.427</td>
<td>0.000610</td>
<td>*** Highly significant</td>
</tr>
<tr class="even">
<td>n_bach</td>
<td>0.0007563</td>
<td>0.0001981</td>
<td>3.817</td>
<td>0.000135</td>
<td>*** Highly significant</td>
</tr>
<tr class="odd">
<td>n_mast</td>
<td>-0.0004373</td>
<td>0.0002131</td>
<td>-2.052</td>
<td>0.040140</td>
<td>* Significant</td>
</tr>
<tr class="even">
<td>n_doc</td>
<td>0.005749</td>
<td>0.001520</td>
<td>3.782</td>
<td>0.000156</td>
<td>*** Highly significant</td>
</tr>
<tr class="odd">
<td>tuition_fees</td>
<td>0.00007245</td>
<td>5.630e-06</td>
<td>12.868</td>
<td>&lt; 2e-16</td>
<td>*** Highly significant</td>
</tr>
<tr class="even">
<td>percent_fin_aid</td>
<td>-0.03674</td>
<td>0.006666</td>
<td>-5.512</td>
<td>3.56e-08</td>
<td>*** Highly significant</td>
</tr>
<tr class="odd">
<td>avg_salary</td>
<td>0.00002599</td>
<td>4.396e-06</td>
<td>5.912</td>
<td>3.39e-09</td>
<td>*** Highly significant</td>
</tr>
</tbody>
</table>
<p>First lets take a look at the model coefficients:</p>
<ul>
<li><strong>Intercept</strong>: The intercept value (-0.4732) represents the log-odds of a university having a “good” graduation rate when all predictor variables are set to zero. The p-value (0.515) indicates that the intercept is not statistically significant, which isn’t a concern because our primary interest is in understanding the relationship between the independent variables and a <code>good_grad_rate</code>.</li>
<li><strong>total_enroll</strong>: For each additional unit increase in total enrollment, the log-odds of having a good graduation rate decrease by 0.0001054. This effect is statistically significant (*).</li>
<li><strong>pct_admitted</strong>: A 1% increase in the percentage of students admitted leads to a decrease in the log-odds of having a good graduation rate by 0.01357. This effect is highly significant (***).</li>
<li><strong>n_bach</strong>: Each additional bachelor’s degree awarded is associated with an increase in the log-odds of a good graduation rate by 0.0007563, and this effect is highly significant (***).</li>
<li><strong>n_mast</strong>: Each additional master’s degree awarded is associated with a slight decrease in the log-odds by 0.0004373, and this effect is marginally significant (*).</li>
<li><strong>n_doc</strong>: Each additional doctoral degree awarded is associated with an increase in the log-odds of a good graduation rate by 0.005749, and this effect is highly significant (***).</li>
<li><strong>tuition_fees</strong>: An increase of one unit in tuition fees is associated with a significant increase in the log-odds of having a good graduation rate by 0.00007245 (***).</li>
<li><strong>percent_fin_aid</strong>: A 1% increase in students receiving financial aid is associated with a decrease in the log-odds of having a good graduation rate by 0.03674, and this effect is highly significant (***).</li>
<li><strong>avg_salary</strong>: Each additional unit in average salary for instructional staff is associated with an increase in the log-odds of having a good graduation rate by 0.00002599, and this effect is highly significant (***).</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Significance codes (***, **, *) provide a quick way to understand the strength of the evidence against the null hypothesis for each predictor in a regression model. Here’s a more detailed explanation:</p>
<ul>
<li><p><strong>*** Highly significant (p &lt; 0.001)</strong>. This indicates a <strong>very strong</strong> evidence against the null hypothesis (which typically states that the predictor has no effect on the outcome variable). A p-value less than 0.001 means there’s less than a 0.1% chance that the observed relationship is due to random chance. Therefore, we have very high confidence that this predictor is indeed related to the outcome variable.</p></li>
<li><p><strong>** Significant (p &lt; 0.01)</strong>. This indicates <strong>strong</strong> evidence against the null hypothesis. A p-value between 0.001 and 0.01 means there’s less than a 1% chance that the observed relationship is due to random chance. We can still be quite confident that this predictor is related to the outcome variable, though not as strong as in the previous category.</p></li>
<li><p><strong>* Marginally significant (p &lt; 0.05)</strong>. This indicates <strong>moderate</strong> evidence against the null hypothesis. A p-value between 0.01 and 0.05 means there’s less than a 5% chance that the observed relationship is due to random chance. While this predictor may have a real effect on the outcome variable, the evidence is weaker compared to predictors with smaller p-values.</p></li>
</ul>
</div>
</div>
<p>Now let’s take a look a key Model Fit Statistic, the <strong>Akaike Information Criterion (AIC)</strong>, which is a metric used to evaluate how well a model fits the data while also considering the complexity of the model. It not only evaluates how well the model explains the data but also penalizes the model for having too many predictors.</p>
<p>Our model has an AIC Value of 1387.5; however, you can’t interpret the AIC value in isolation as “good” or “bad”; instead, you compare it across models.</p>
<ul>
<li>A <strong>lower AIC value</strong> indicates a model that achieves a better balance between goodness-of-fit and simplicity.</li>
<li>It means the model provides a good explanation of the data without being overly complex.</li>
</ul>
<p>If we were add or remove predictors from our model to test other models, the model with the <strong>lowest AIC</strong> would be considered the best among the compared models, as it suggests the optimal combination of fit and simplicity.</p>
<p><strong>Summary</strong></p>
<p>Overall, the model appears to be a good fit for understanding factors related to a “good” graduation rate, with tuition fees, percent financial aid, and average salary being especially influential factors. Specifically, the predictors <code>pct_admitted</code>, <code>n_bach</code>, <code>n_doc</code>, <code>tuition_fees</code>, <code>percent_fin_aid</code>, and <code>avg_salary</code> are highly significant in predicting whether a university has a good graduation rate.</p>
</section>
<section id="your-turn-9" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-9"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>In the space below, note a few similarities and/or differences between the model and it’s interpretation described above and the model you ran with your own determination of a “good” graduation rate:</p>
<ul>
<li><p>NOTE 1</p></li>
<li><p>NOTE 2</p></li>
<li><p>NOTE 3</p></li>
</ul>
</section>
</section>
<section id="a.-supervised-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="a.-supervised-machine-learning">4a. Supervised Machine Learning</h3>
<p>Recall from our readings that there are two general types of machine learning approaches: unsupervised and supervised learning. In this section we focus on supervised learning models, which are used to quantify relationships between features (e.g., % of students admitted and tuition fees) and a known outcome (i.e., a good graduation rate). These models can be used for statistical inference, as illustrated above, or primarily for prediction purposes, as we’ll illustrate below.</p>
<p>In this section we’ll learn five basic machine learning steps for building, training, and evaluating a model. Specifically, we will use the {tidymodels} package in R and learn how to:</p>
<ol type="1">
<li><p><strong>Split Data</strong> into a training and test set that will be used to develop a predictive model;</p></li>
<li><p><strong>Create a “Recipe”</strong> for our predictive model and learn how to deal with data that we would like to use as predictors;</p></li>
<li><p><strong>Specify model and workflow</strong> by selecting the <em>functional form</em> of the model that we want and using a <em>model workflow</em> to pair our model and recipe together;</p></li>
<li><p><strong>Fit model</strong> to our <em>training</em> <em>set</em> using logistic regression;</p></li>
<li><p><strong>Assess Accuracy</strong> of our model on our <em>testing set</em> to see how well our model can “predict” a good graduation rate.</p></li>
</ol>
<section id="step-1.-split-data" class="level4">
<h4 class="anchored" data-anchor-id="step-1.-split-data">Step 1. Split data</h4>
<p>The authors of Data Science in Education Using R (Estrellado et al.,2020) remind us that:</p>
<blockquote class="blockquote">
<p>At its core, machine learning is the process of “showing” your statistical model only some of the data at once and training the model to predict accurately on that training dataset (this is the “learning” part of machine learning). Then, the model as developed on the training data is shown new data - data you had all along, but hid from your computer initially - and you see how well the model that you developed on the training data performs on this new testing data. Eventually, you might use the model on entirely new data.</p>
</blockquote>
<p><strong>Training and Testing Sets</strong></p>
<p>It is therefore common when beginning a machine learning project to <a href="https://bookdown.org/max/FES/data-splitting.html">separate the data set</a> into two partitions:</p>
<ul>
<li><p>The <em>training set</em> is used to estimate, develop and compare models; feature engineering techniques; tune models, etc.</p></li>
<li><p>The <em>test set</em> is held in reserve until the end of the project, at which point there should only be one or two models under serious consideration. It is used as an unbiased source for measuring final model performance.</p></li>
</ul>
<p>There are different ways to create these partitions of the data and there is no uniform guideline for determining how much data should be set aside for testing. The proportion of data can be driven by many factors, including the size of the original pool of samples and the total number of predictors.&nbsp;</p>
<p>After you decide how much to set aside, the most common approach for actually partitioning your data is to use a random sample. For our purposes, we’ll use random sampling to select 20% for the test set and use the remainder for the training set, which are the defaults for the {<a href="https://tidymodels.github.io/rsample/">rsample</a>} package.</p>
<p><strong>Split data set</strong></p>
<p>To split our data, we will be using our first {tidymodels} function - <code>initial_split()</code>.</p>
<p>The function <code>initial_split()</code> function from the {rsample} package takes the original data and saves the information on how to make the partitions. The {rsample} package has two aptly named functions for created a training and testing data set called <code>training()</code> and <code>testing()</code>, respectively.</p>
<p>We also specify the strata to ensure there is not misbalance in the dependent variable (good_grad_rate).</p>
<p>Run the following code to split the data:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training (80%) and testing (20%) sets</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) <span class="co"># Setting a seed for reproducibility</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>data_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(ipeds, <span class="at">prop =</span> <span class="fl">0.8</span>, <span class="at">strata =</span> good_grad_rate) </span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create training and testing datasets</span></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>training_data <span class="ot">&lt;-</span> <span class="fu">training</span>(data_split)</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>testing_data <span class="ot">&lt;-</span> <span class="fu">testing</span>(data_split)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s break down what we just did a little further:</p>
<ul>
<li><p><code>initial_split(ipeds, prop = 0.8)</code> splits our <code>ipeds</code> data into 80% for training and 20% for testing.</p></li>
<li><p><code>strata = good_grad_rate</code> ensures stratified sampling, meaning the proportion of <code>good_grad_rate</code> categories is maintained in both the training and testing sets.</p></li>
<li><p><code>training(data_split)</code> extracts the training set.</p></li>
<li><p><code>testing(data_split)</code> Extracts the testing set.</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Note</strong>: Since random sampling uses random numbers, it is important to set the random number seed using the <code>set.seed()</code> function. This ensures that the random numbers can be reproduced at a later time (if needed). Here we use <code>12345</code> but any number will work!</p>
</div>
</div>
</section>
<section id="your-turn-10" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-10"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>Go ahead and type <code>data_train</code> and <code>data_test</code> into the console (in steps) to check that this data set indeed has 80% of the number of observations as in the larger data. Do that in the chunk below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>training_data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3,054 × 14
   name    title_iv carnegie_class state total_enroll pct_admitted n_bach n_mast
   &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;        &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
 1 Alabam… Title I… Master's Coll… Alab…         6007           68    511    249
 2 Univer… Title I… Doctoral Univ… Alab…        21639           87   2785   2512
 3 Univer… Title I… Doctoral Univ… Alab…         9237           78   1624    570
 4 Alabam… Title I… Doctoral/Prof… Alab…         3828           97    480    119
 5 Centra… Title I… Associate's C… Alab…         1777           NA     NA     NA
 6 Athens… Title I… Baccalaureate… Alab…         2894           NA    738     80
 7 Auburn… Title I… Master's Coll… Alab…         5109           92    672    300
 8 Birmin… Title I… Baccalaureate… Alab…          975           57    263      0
 9 Chatta… Title I… Associate's C… Alab…         1641           NA     NA     NA
10 South … Title I… Baccalaureate… Alab…          361           NA     31     17
# ℹ 3,044 more rows
# ℹ 6 more variables: n_doc &lt;dbl&gt;, tuition_fees &lt;dbl&gt;, grad_rate &lt;dbl&gt;,
#   percent_fin_aid &lt;dbl&gt;, avg_salary &lt;dbl&gt;, good_grad_rate &lt;fct&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>testing_data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 764 × 14
   name    title_iv carnegie_class state total_enroll pct_admitted n_bach n_mast
   &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;        &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
 1 Amridg… Title I… Master's Coll… Alab…          647           NA     54     96
 2 Faulkn… Title I… Master's Coll… Alab…         2817           82    448    347
 3 J. F. … Title I… Associate's C… Alab…          976           NA     NA     NA
 4 Stillm… Title I… Baccalaureate… Alab…          744           65    100      0
 5 United… Title I… Special Focus… Alab…          240          100     11     25
 6 Alaska… Title I… Baccalaureate… Alas…          595           99     63     41
 7 Carrin… Title I… Special Focus… Ariz…         1048           NA     NA     NA
 8 Carrin… Title I… Special Focus… Ariz…          446           NA     NA     NA
 9 Brookl… Title I… Special Focus… Ariz…          888           NA    248     16
10 Arizon… Title I… Doctoral Univ… Ariz…        80065           90  14960   3727
# ℹ 754 more rows
# ℹ 6 more variables: n_doc &lt;dbl&gt;, tuition_fees &lt;dbl&gt;, grad_rate &lt;dbl&gt;,
#   percent_fin_aid &lt;dbl&gt;, avg_salary &lt;dbl&gt;, good_grad_rate &lt;fct&gt;</code></pre>
</div>
</div>
</section>
<section id="step-2-create-a-recipe" class="level4">
<h4 class="anchored" data-anchor-id="step-2-create-a-recipe">Step 2: Create a “Recipe”</h4>
<p>In this section, we introduce another tidymodels package named {<a href="https://recipes.tidymodels.org/">recipes</a>}, which is designed to help you prepare your data <em>before</em> training your model. <strong>Recipes</strong> are built as a series of preprocessing steps, such as:</p>
<ul>
<li><p>converting qualitative predictors to indicator variables (also known as dummy variables),</p></li>
<li><p>transforming data to be on a different scale (e.g., taking the logarithm of a variable),</p></li>
<li><p>transforming whole groups of predictors together,</p></li>
<li><p>extracting key features from raw variables (e.g., getting the day of the week out of a date variable), and so on.</p></li>
</ul>
<p>If you are familiar with R’s formula interface, a lot of this might sound familiar and is very similar to what we did above in the statistical inference section. Recipes can be used to do many of the same things, but they have a much wider range of possibilities.</p>
<p><strong>Add a Formula</strong></p>
<p>To get started, let’s create a recipe for a simple logistic regression model. The <a href="https://recipes.tidymodels.org/reference/recipe.html"><code>recipe()</code>function</a> as we used it here has two arguments:</p>
<ul>
<li><p>A <strong>formula</strong>. Any variable on the left-hand side of the tilde (<code>~</code>) is considered the model outcome (<code>code</code>, in our present case). On the right-hand side of the tilde are the predictors. Variables may be listed by name, or you can use the dot (<code>.</code>) to indicate all other variables as predictors.</p></li>
<li><p>The <strong>data</strong>. A recipe is associated with the data set used to create the model. This will typically be the <em>training</em> set, so <code>data = train_data</code> here. Naming a data set doesn’t actually change the data itself; it is only used to catalog the names of the variables and their types, like factors, integers, dates, etc.</p></li>
</ul>
<p>Run the following code chunk to create a recipe where we predict <code>good_grad_rate</code> (the outcome variable) using the same predictor variables we used above:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>my_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(good_grad_rate <span class="sc">~</span> </span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>                   total_enroll <span class="sc">+</span> </span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>                   pct_admitted <span class="sc">+</span> </span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>                   n_bach <span class="sc">+</span> </span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>                   n_mast <span class="sc">+</span> </span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>                   n_doc <span class="sc">+</span> </span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>                   tuition_fees <span class="sc">+</span> </span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>                   percent_fin_aid <span class="sc">+</span> </span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>                   avg_salary, </span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> training_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Code Explanation</strong></p>
<p>Again, let’s unpack what is happening in this code:</p>
<ul>
<li><p>This code defines a recipe that outlines which variables (<code>total_enroll</code>, <code>pct_admitted</code>, etc.) will be used to predict the outcome (<code>good_grad_rate</code>) and ensures that this process is applied to the <code>training_data</code>.</p></li>
<li><p>At this stage, no actual preprocessing (e.g., scaling, imputation) is performed. The recipe simply sets up the structure, which can be extended later to include data cleaning, transformations, or feature engineering as needed.</p></li>
</ul>
<p>By defining the recipe, you make the analysis more modular, allowing you to handle data preprocessing consistently and efficiently before training the machine learning model. These topics are covered in much greater depth in the Machine Learning course.</p>
</section>
</section>
<section id="step-3-specify-a-model" class="level3">
<h3 class="anchored" data-anchor-id="step-3-specify-a-model">Step 3: Specify a Model</h3>
<p>With tidymodels, we next start building a model by specifying the <em>functional form</em> of the model that we want using the <a href="https://tidymodels.github.io/parsnip/">{parsnip} package</a>. Since our outcome is binary, the model type we will use is&nbsp;“<a href="https://parsnip.tidymodels.org/reference/logistic_reg.html">logistic regression</a>.” We can declare this with <code>logistic_reg()</code> and assign to an object we will later use in our workflow:</p>
<section id="your-turn-11" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-11"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>In the code chunk below, specify our model by assigning the <code>logistic_reg()</code> function to a new object named <code>my_model</code> :</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># specify model</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>my_model <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>()</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>my_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Logistic Regression Model Specification (classification)

Computational engine: glm </code></pre>
</div>
</div>
<p>Great! If you did this correctly you should see the following output:</p>
<pre><code>Logistic Regression Model Specification (classification)

Computational engine: glm </code></pre>
</section>
<section id="add-model-and-recipe-to-workflow" class="level4">
<h4 class="anchored" data-anchor-id="add-model-and-recipe-to-workflow"><strong>Add Model and Recipe to Workflow</strong></h4>
<p>Finally, we’ll create a “workflow”, which pairs a model and recipe together. Although we’ll just be using a single recipe This is a straightforward approach because different recipes are often needed for different models, so when a model and recipe are bundled, it becomes easier to train and test <em>workflows</em>.</p>
<p>We’ll use the {<a href="https://workflows.tidymodels.org/">workflows</a>} package from tidymodels to bundle our parsnip model (<code>my_model</code>) with our recipe (<code>my_recipe</code>).</p>
<p>Add your model and recipe (see their names above)!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>my_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span> <span class="co"># create a workflow</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_model</span>(my_model) <span class="sc">|&gt;</span> <span class="co"># add the model we wrote above</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">add_recipe</span>(my_recipe) <span class="co"># add our recipe we wrote above</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="step-4-fit-model-to-training-data" class="level3">
<h3 class="anchored" data-anchor-id="step-4-fit-model-to-training-data">Step 4: Fit Model to Training Data</h3>
<p>Now that we have a single workflow that can be used to prepare the recipe and train the model from the resulting predictors, we can use the <code>fit()</code> function to fit our model to our <code>training_data</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>fit_model <span class="ot">&lt;-</span> <span class="fu">fit</span>(my_workflow, training_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="your-turn-12" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-12"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>Type the output of the above function (the name you assigned the output to) below; this is the final, fitted model—one that can be interpreted further in the next step!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>fit_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>══ Workflow [trained] ══════════════════════════════════════════════════════════
Preprocessor: Recipe
Model: logistic_reg()

── Preprocessor ────────────────────────────────────────────────────────────────
0 Recipe Steps

── Model ───────────────────────────────────────────────────────────────────────

Call:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)

Coefficients:
    (Intercept)     total_enroll     pct_admitted           n_bach  
     -4.055e-01       -9.880e-05       -1.253e-02        7.103e-04  
         n_mast            n_doc     tuition_fees  percent_fin_aid  
     -4.400e-04        5.773e-03        7.111e-05       -3.749e-02  
     avg_salary  
      2.588e-05  

Degrees of Freedom: 1294 Total (i.e. Null);  1286 Residual
  (1759 observations deleted due to missingness)
Null Deviance:      1635 
Residual Deviance: 1101     AIC: 1119</code></pre>
</div>
</div>
<p>Great work!</p>
</section>
</section>
<section id="step-5-assess-accuracty-on-test-data" class="level3">
<h3 class="anchored" data-anchor-id="step-5-assess-accuracty-on-test-data">Step 5: Assess Accuracty on Test Data</h3>
<p>Finally, run the following code snippet to generate predictions from the trained logistic regression model (<code>fit_model</code>) on the test dataset (<code>testing_data</code>) and then combine those predictions with the original test data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit_model, testing_data) <span class="sc">|&gt;</span> </span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(testing_data)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>predictions</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 764 × 15
   .pred_class name      title_iv carnegie_class state total_enroll pct_admitted
   &lt;fct&gt;       &lt;chr&gt;     &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;        &lt;dbl&gt;        &lt;dbl&gt;
 1 &lt;NA&gt;        Amridge … Title I… Master's Coll… Alab…          647           NA
 2 0           Faulkner… Title I… Master's Coll… Alab…         2817           82
 3 &lt;NA&gt;        J. F. Dr… Title I… Associate's C… Alab…          976           NA
 4 0           Stillman… Title I… Baccalaureate… Alab…          744           65
 5 &lt;NA&gt;        United S… Title I… Special Focus… Alab…          240          100
 6 0           Alaska P… Title I… Baccalaureate… Alas…          595           99
 7 &lt;NA&gt;        Carringt… Title I… Special Focus… Ariz…         1048           NA
 8 &lt;NA&gt;        Carringt… Title I… Special Focus… Ariz…          446           NA
 9 &lt;NA&gt;        Brooklin… Title I… Special Focus… Ariz…          888           NA
10 1           Arizona … Title I… Doctoral Univ… Ariz…        80065           90
# ℹ 754 more rows
# ℹ 8 more variables: n_bach &lt;dbl&gt;, n_mast &lt;dbl&gt;, n_doc &lt;dbl&gt;,
#   tuition_fees &lt;dbl&gt;, grad_rate &lt;dbl&gt;, percent_fin_aid &lt;dbl&gt;,
#   avg_salary &lt;dbl&gt;, good_grad_rate &lt;fct&gt;</code></pre>
</div>
</div>
<p>Again, let’s breakdown what is happening with this code and then interpret the output:</p>
<ul>
<li>The <code>predict()</code> function produces a set of predictions for the outcome variable (<code>good_grad_rate</code>) for each observation in the <code>testing_data</code>.
<ul>
<li><code>fit_model</code>: The logistic regression model that was previously trained on the training data.</li>
<li><code>testing_data</code>: The dataset used to test the model’s performance, which contains new, unseen data.</li>
</ul></li>
<li>The <code>bind_cols()</code> function merges the predicted values with the original test dataset row by row, resulting in a data frame that contains both the actual values (from <code>testing_data</code>) and the model’s predicted values side by side.</li>
<li>The <code>predictions</code> object now contains a combined dataset that includes:
<ul>
<li>All original columns from <code>testing_data</code>.</li>
<li>A new column (or columns) with the predicted values from the model, allowing you to compare the actual values with the predicted ones.</li>
</ul></li>
<li>When you print <code>predictions</code>, you’ll see a data frame that includes both the original test data and the predicted values for <code>good_grad_rate</code>. This allows you to analyze how well the model’s predictions match the actual values.</li>
</ul>
<p>This step is crucial for evaluating the model’s accuracy and effectiveness in making predictions on unseen data, which helps determine how well the model generalizes beyond the training data.</p>
<p>The output represents the predicted classification (<code>.pred_class</code>) for whether an institution has a “good” graduation rate (<code>1</code> indicates “good,” and <code>0</code> indicates “not good”) based on the trained logistic regression model, along with some details about each institution, such as their <code>name</code> and <code>title_iv</code> status.</p>
<p><strong>Interpretation of the Output:</strong></p>
<ol type="1">
<li><p><strong><code>.pred_class</code>:</strong> This column contains the predicted class labels for each institution:</p>
<ul>
<li><strong><code>1</code></strong>: The model predicts that the institution has a “good” graduation rate.</li>
<li><strong><code>0</code></strong>: The model predicts that the institution does not have a “good” graduation rate.</li>
<li><strong><code>NA</code></strong>: The model could not make a prediction for these institutions. This might be due to missing data in the predictor variables or data preprocessing issues that caused the model to be unable to generate a prediction.</li>
</ul></li>
<li><p><strong><code>name</code>:</strong> This column lists the names of the institutions.</p></li>
<li><p><strong><code>title_iv</code>:</strong> This column indicates whether the institution is a “Title IV postsecondary institution,” meaning they are eligible for federal financial aid programs.</p></li>
</ol>
<ul>
<li>The model has successfully classified some institutions into having either a good (<code>1</code>) or not good (<code>0</code>) graduation rate.</li>
<li>The presence of <code>NA</code> values suggests that data issues (e.g., missing predictor values or cases where the model couldn’t confidently make a prediction) need to be investigated further to ensure comprehensive predictions.</li>
</ul>
<section id="accuracy-metrics" class="level4">
<h4 class="anchored" data-anchor-id="accuracy-metrics">Accuracy Metrics</h4>
<p>Our final step is to assess model accuracy by comparing the predicted values (<code>.pred_class</code>) with the actual <code>good_grad_rate</code> values for the test set to evaluate the model’s performance on predicting graduation rates.</p>
<p>So, how accurate was our predictive model? Consider how well our model would have done by chance alone – what would the accuracy be in that case (with the model predicting pass one-half of the time)?</p>
<p>Run the following code</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate accuracy on the testing set</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>accuracy <span class="ot">&lt;-</span> predictions <span class="sc">|&gt;</span> </span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">metrics</span>(<span class="at">truth =</span> good_grad_rate, <span class="at">estimate =</span> .pred_class) <span class="sc">|&gt;</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">"accuracy"</span>)</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Print accuracy</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>accuracy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
  .metric  .estimator .estimate
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
1 accuracy binary         0.819</code></pre>
</div>
</div>
<p>You probably saw an output that looks something similar to the table below:</p>
<table class="table">
<thead>
<tr class="header">
<th>.metric</th>
<th>.estimator</th>
<th>.estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>accuracy</td>
<td>binary</td>
<td>0.8193146</td>
</tr>
</tbody>
</table>
<p>Let’s break these down:</p>
<ol type="1">
<li><strong><code>.metric = "accuracy"</code>:</strong> Indicates that the metric being reported is <strong>accuracy</strong>.</li>
<li><strong><code>.estimator = "binary"</code>:</strong> Specifies that the model is a <strong>binary classifier</strong>, meaning the model predicts one of two possible outcomes (in this case, predicting whether <code>good_grad_rate</code> is 0 or 1).</li>
<li><strong><code>.estimate = 0.8193146</code>:</strong> This value represents the accuracy of the model’s predictions on the test dataset. An accuracy of <strong>0.8193</strong> (or <strong>81.93%</strong>) means that the model correctly predicted whether universities have a “good” graduation rate in approximately 81.93% of the cases in the test set.</li>
</ol>
<p><strong>Accuracy</strong> is the proportion of correct predictions made by the model out of all predictions. It is calculated as:</p>
<p><span class="math inline">\(\text{Accuracy} = \frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}}\)</span></p>
<p>Accurracy, like AIC discussed above, is just one of several metrics we could use to tell us how well our model performs. This metric is an essential indicator of how well the model generalizes to unseen data, which is crucial for evaluating its overall performance.</p>
<p>The model’s accuracy on the test dataset reveals that the model correctly predicts the outcome (good graduation rate) approximately 81.93% of the time, which on the surfance seems suggests that it is pretty good at predicting whether a college has a good graduation rate.</p>
<p><strong>Code Explanation</strong></p>
<p>Before moving on, let’s also break down the code we used to generate this output:</p>
<ul>
<li><p>The <code>metrics()</code> function calculates various performance metrics for the model’s predictions, which we saved as <code>predictions</code>.</p>
<ul>
<li><p><code>truth = good_grad_rate</code>: Specifies the actual values of the target variable (<code>good_grad_rate</code>) from the test data.</p></li>
<li><p><code>estimate = .pred_class</code>: Refers to the predicted values (i.e., the predicted class labels <code>0</code> or <code>1</code>) generated by the model.</p></li>
</ul></li>
</ul>
<p>This step produces a data frame containing several evaluation metrics such as accuracy, precision, recall, etc., that compare the actual values (<code>truth</code>) with the predicted values (<code>estimate</code>), which we then passed on to:</p>
<ul>
<li><p><strong><code>filter(.metric == "accuracy")</code></strong>, which extracts only the row corresponding to the “accuracy” metric from the resulting data frame.</p></li>
<li><p>The <code>accuracy</code> object now contains a single row representing the accuracy of the model on the test data.</p></li>
</ul>
</section>
<section id="your-turn-13" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-13"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>The key to observe at this point is what is similar and different between the two approaches (regression and supervised machine learning). Both used the same underlying statistical model, but had some stark differences. Add two or more similarities and two or more differences (no wrong answers!) below.</p>
<p>Similarities:</p>
<ul>
<li>SIMILARITY 1</li>
<li>SIMILARITY 2</li>
</ul>
<p>Differences:</p>
<ul>
<li><p>DIFFERENCE 1</p></li>
<li><p>DIFFERENCE 2</p></li>
</ul>
</section>
</section>
</section>
<section id="communicate" class="level2">
<h2 class="anchored" data-anchor-id="communicate">5. COMMUNICATE</h2>
<p>Recall that the final step in the workflow/process is sharing the results of your analysis with wider audience. Krumm et al.&nbsp;(2018) have outlined the following 3-step process for communicating with education stakeholders findings from an analysis:</p>
<ol type="1">
<li><p><strong>Select.</strong> Communicating what one has learned involves selecting among those analyses that are most important and most useful to an intended audience, as well as selecting a form for displaying that information, such as a graph or table in static or interactive form, i.e.&nbsp;a “data product.”</p></li>
<li><p><strong>Polish</strong>. After creating initial versions of data products, research teams often spend time refining or polishing them, by adding or editing titles, labels, and notations and by working with colors and shapes to highlight key points.</p></li>
<li><p><strong>Narrate.</strong> Writing a narrative to accompany the data products involves, at a minimum, pairing a data product with its related research question, describing how best to interpret the data product, and explaining the ways in which the data product helps answer the research question.</p></li>
</ol>
<p>In this case study, we focused applying some basic machine learning techniques to help us understand how a predictive model used in predict colleges with good graduation rates. Specifically, we made a very crude first attempt at developing a model using machine learning techniques that seemed to perform reasonably well as predicting graduation rates.</p>
<p>For this case study, let’s simply focus on return to our research question:</p>
<blockquote class="blockquote">
<p>How well can we predict drop out rates for among four-year universities?</p>
</blockquote>
<section id="your-turn-14" class="level4">
<h4 class="anchored" data-anchor-id="your-turn-14"><strong>👉 Your Turn</strong> <strong>⤵</strong></h4>
<p>At the beginning of this section you chose for yourself what constitutes a good graduation rate. Now create your own recipe and see how it performs.</p>
<p>Use the code chunk below to repeat our machine learning steps but this time modify the recipe to see if you can create a model that predicts graduation outcomes with a higher level of accuracy. Feel free to copy and paste from our code above to assist you with this process.</p>
<p>What did you find? How accurately were you able to predict “good” graduation rates? Focus on what you would communicate about this analysis to a general audience, again, keeping in mind this is based on your very initial interpretations.</p>
<ul>
<li>YOUR RESPONSE HERE</li>
</ul>
<p><strong>Note</strong>: This exercise (especially the supervised machine learning model and its output) is very likely new, and this is meant to elicit initial perceptions, and not the right answer, so don’t stress to much about creating accurate models.</p>
</section>
<section id="congratulations" class="level3">
<h3 class="anchored" data-anchor-id="congratulations">Congratulations!</h3>
<p>You’ve completed the Unit 2 Case Study: Introduction to Machine Learning! To “turn in” your work, you can click the “Render” icon in the menu bar above. This will create a HTML report in your Files pane that serves as a record of your completed assignment and that can be opened in a browser or shared on the web.</p>

</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-krumm2018" class="csl-entry" role="listitem">
Krumm, Andrew, Barbara Means, and Marie Bienkowski. 2018. <em>Learning Analytics Goes to School</em>. Routledge. <a href="https://doi.org/10.4324/9781315650722">https://doi.org/10.4324/9781315650722</a>.
</div>
<div id="ref-wickham2023r" class="csl-entry" role="listitem">
Wickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. <em>R for Data Science</em>. " O’Reilly Media, Inc.". <a href="https://r4ds.hadley.nz">https://r4ds.hadley.nz</a>.
</div>
<div id="ref-zong2024modeling" class="csl-entry" role="listitem">
Zong, Chen, and Alan Davis. 2024. <span>“Modeling University Retention and Graduation Rates Using IPEDS.”</span> <em>Journal of College Student Retention: Research, Theory &amp; Practice</em> 26 (2): 311–33.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>